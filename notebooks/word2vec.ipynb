{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/footballest/ml-blog-jaketae/blob/main/notebooks/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9149dea1",
      "metadata": {
        "id": "9149dea1"
      },
      "source": [
        "\n",
        "# TITLE – Replication/Notes (test)\n",
        "\n",
        "**Original post**: <https://jaketae.github.io/study/word2vec/>  \n",
        "**Your name**: <YOUR_NAME>  \n",
        "**Last updated**: <YYYY-MM-DD>\n",
        "\n",
        "---\n",
        "\n",
        "## Goals\n",
        "- Summarize key ideas in my own words\n",
        "- Implement the core algorithm from scratch (where feasible)\n",
        "- Compare with a reference implementation (if relevant)\n",
        "- Run a tiny experiment and record results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f15a72c",
      "metadata": {
        "id": "6f15a72c",
        "outputId": "b6ece359-1616-48c7-f052-ac6a63d8af7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Workspace ready: /content/drive/MyDrive/ml-blog\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@title Setup (mount Drive and create workspace paths)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "BASE_DIR = '/content/drive/MyDrive/ml-blog'\n",
        "DATA_DIR = f'{BASE_DIR}/data'\n",
        "IMG_DIR = f'{BASE_DIR}/images'\n",
        "ART_DIR = f'{BASE_DIR}/artifacts'\n",
        "\n",
        "import os\n",
        "for d in [BASE_DIR, DATA_DIR, IMG_DIR, ART_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "print(\"Workspace ready:\", BASE_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54a6d521",
      "metadata": {
        "id": "54a6d521",
        "outputId": "c6e01fb6-8b44-4f17-b480-a74c20239122",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch: 2.8.0+cu126\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@title Environment check (optional)\n",
        "try:\n",
        "    import torch\n",
        "    print(\"PyTorch:\", torch.__version__)\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"CUDA device:\", torch.cuda.get_device_name(0))\n",
        "except Exception as e:\n",
        "    print(\"Torch not available by default on Colab runtimes; that's okay.\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c49ee364",
      "metadata": {
        "id": "c49ee364"
      },
      "source": [
        "## Theory recap\n",
        "Write the core ideas, equations, and intuition here."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c0b83cd",
      "metadata": {
        "id": "7c0b83cd"
      },
      "source": [
        "## Implementation (from scratch or minimal lib use)\n",
        "Add your code here."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4d6793a",
      "metadata": {
        "id": "a4d6793a"
      },
      "source": [
        "## Experiments\n",
        "Describe the dataset, metrics, and small experiments you ran."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7df67e3",
      "metadata": {
        "id": "f7df67e3"
      },
      "source": [
        "## Results & Discussion\n",
        "What worked? What didn’t? What would you try next?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cccd93c4",
      "metadata": {
        "id": "cccd93c4"
      },
      "source": [
        "## References\n",
        "- Add links to papers, docs, and the original post."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimal Word2Vec (SGNS) on a tiny corpus\n",
        "import math, random, re, collections\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "text = \"\"\"\n",
        "we all learn by building small models from scratch\n",
        "small models teach big ideas\n",
        "we learn by repeating ideas and connecting ideas to code\n",
        "\"\"\".strip().lower()\n",
        "\n",
        "# --- tokenize & vocab ---\n",
        "tokens = re.findall(r\"[a-z']+\", text)\n",
        "freq = collections.Counter(tokens)\n",
        "itos = [w for w,c in freq.items() if c>=1]\n",
        "stoi = {w:i for i,w in enumerate(itos)}\n",
        "ids = [stoi[w] for w in tokens]\n",
        "\n",
        "# --- negative sampling distribution (unigram^0.75) ---\n",
        "counts = torch.tensor([freq[w] for w in itos], dtype=torch.float)\n",
        "neg_dist = (counts ** 0.75) / (counts ** 0.75).sum()\n",
        "\n",
        "# --- make (center, context) pairs ---\n",
        "window = 2\n",
        "pairs = []\n",
        "for i, c in enumerate(ids):\n",
        "    L = max(0, i - window); R = min(len(ids), i + window + 1)\n",
        "    for j in range(L, R):\n",
        "        if j == i: continue\n",
        "        pairs.append((c, ids[j]))\n",
        "\n",
        "class SGNSDataset(Dataset):\n",
        "    def __init__(self, pairs, neg_dist, num_neg=5):\n",
        "        self.pairs = pairs\n",
        "        self.neg_dist = neg_dist\n",
        "        self.num_neg = num_neg\n",
        "    def __len__(self): return len(self.pairs)\n",
        "    def __getitem__(self, idx):\n",
        "        c,o = self.pairs[idx]\n",
        "        neg = torch.multinomial(self.neg_dist, self.num_neg, replacement=True)\n",
        "        return torch.tensor(c), torch.tensor(o), neg\n",
        "\n",
        "ds = SGNSDataset(pairs, neg_dist, num_neg=5)\n",
        "dl = DataLoader(ds, batch_size=64, shuffle=True)\n",
        "\n",
        "# --- model: two embedding tables ---\n",
        "class SGNS(nn.Module):\n",
        "    def __init__(self, vocab_size, d=50):\n",
        "        super().__init__()\n",
        "        self.in_emb  = nn.Embedding(vocab_size, d)\n",
        "        self.out_emb = nn.Embedding(vocab_size, d)\n",
        "        nn.init.uniform_(self.in_emb.weight,  -0.5/d, 0.5/d)\n",
        "        nn.init.zeros_(self.out_emb.weight)\n",
        "    def forward(self, c, pos, neg):\n",
        "        # c: (B,), pos: (B,), neg: (B, K)\n",
        "        vc  = self.in_emb(c)              # (B, d)\n",
        "        uo  = self.out_emb(pos)           # (B, d)\n",
        "        un  = self.out_emb(neg)           # (B, K, d)\n",
        "        pos_score = torch.sum(vc * uo, dim=1)            # (B,)\n",
        "        neg_score = torch.einsum('bd,bkd->bk', vc, un)   # (B, K)\n",
        "        loss = -torch.log(torch.sigmoid(pos_score) + 1e-9).mean() \\\n",
        "               -torch.log(torch.sigmoid(-neg_score) + 1e-9).mean()\n",
        "        return loss\n",
        "    def embeddings(self):\n",
        "        # common to use input table as word vectors\n",
        "        return self.in_emb.weight.data\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = SGNS(len(itos), d=50).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "for epoch in range(20):\n",
        "    total = 0.0\n",
        "    for c,o,n in dl:\n",
        "        c,o,n = c.to(device), o.to(device), n.to(device)\n",
        "        opt.zero_grad()\n",
        "        loss = model(c,o,n)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total += loss.item()*c.size(0)\n",
        "    print(f\"epoch {epoch+1:02d} | loss {total/len(ds):.4f}\")\n",
        "\n",
        "# --- quick nearest neighbors ---\n",
        "with torch.no_grad():\n",
        "    E = nn.functional.normalize(model.embeddings().cpu(), dim=1)\n",
        "    def nn_words(query, topk=5):\n",
        "        q = E[stoi[query]]\n",
        "        sim = (E @ q)\n",
        "        vals, idxs = torch.topk(sim, topk+1)\n",
        "        out = [itos[i] for i in idxs.tolist() if itos[i] != query][:topk]\n",
        "        return out\n",
        "\n",
        "print(\"Neighbors for 'ideas':\", nn_words('ideas'))\n",
        "print(\"Neighbors for 'learn':\", nn_words('learn'))\n"
      ],
      "metadata": {
        "id": "lDbxftrbAZz8",
        "outputId": "cb87ff82-4b5a-4c03-8918-c09983f799d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lDbxftrbAZz8",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 01 | loss 1.3863\n",
            "epoch 02 | loss 1.3851\n",
            "epoch 03 | loss 1.3802\n",
            "epoch 04 | loss 1.3701\n",
            "epoch 05 | loss 1.3592\n",
            "epoch 06 | loss 1.3384\n",
            "epoch 07 | loss 1.3150\n",
            "epoch 08 | loss 1.2928\n",
            "epoch 09 | loss 1.2723\n",
            "epoch 10 | loss 1.2257\n",
            "epoch 11 | loss 1.2243\n",
            "epoch 12 | loss 1.1830\n",
            "epoch 13 | loss 1.1780\n",
            "epoch 14 | loss 1.1348\n",
            "epoch 15 | loss 1.1266\n",
            "epoch 16 | loss 1.0702\n",
            "epoch 17 | loss 1.0821\n",
            "epoch 18 | loss 1.1103\n",
            "epoch 19 | loss 1.0532\n",
            "epoch 20 | loss 1.1340\n",
            "Neighbors for 'ideas': ['repeating', 'to', 'code', 'and', 'connecting']\n",
            "Neighbors for 'learn': ['all', 'by', 'repeating', 'we', 'ideas']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G2VlcwO2AbUF"
      },
      "id": "G2VlcwO2AbUF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KTxqcCBwAcjj"
      },
      "id": "KTxqcCBwAcjj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}